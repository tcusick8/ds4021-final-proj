{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd1d8e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE AS MANY CELLS AS NEEDED\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch import optim\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#from torch.utils.data import TensorDataset, DataLoader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53ffa4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('~/Downloads/X_train.csv')\n",
    "y_train = pd.read_csv('~/Downloads/y_train.csv')\n",
    "X_test = pd.read_csv('~/Downloads/X_test.csv')\n",
    "y_test = pd.read_csv('~/Downloads/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb2fae6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 946,609\n",
      "Using 100,000 samples for Neural Network training\n",
      "X_train shape: (100000, 16)\n",
      "y_train shape: (100000, 2)\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Clean and parse data\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "train_clean = train.dropna()\n",
    "X_train_clean = train_clean.iloc[:, :-1]\n",
    "y_train_clean = train_clean.iloc[:, -1]\n",
    "\n",
    "# Parse coordinates\n",
    "y_coords = y_train_clean.apply(ast.literal_eval)\n",
    "y_clean = np.vstack(y_coords.values)\n",
    "\n",
    "print(f\"Total samples: {len(X_train_clean):,}\")\n",
    "\n",
    "# sample the data \n",
    "sample_size = 100000 \n",
    "np.random.seed(42)\n",
    "sample_indices = np.random.choice(len(X_train_clean), size=sample_size, replace=False)\n",
    "X_train_sample = X_train_clean.iloc[sample_indices].reset_index(drop=True)\n",
    "y_train_sample = y_clean[sample_indices]\n",
    "\n",
    "print(f\"Using {sample_size:,} samples for Neural Network training\")\n",
    "\n",
    "# Update the variables\n",
    "X_train = X_train_sample\n",
    "y_train = pd.DataFrame(y_train_sample, columns=['lat', 'lon'])\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "491de14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae8abdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.module_list = nn.ModuleList([\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)  # 2 outputs: latitude and longitude\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.module_list:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c51bcbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final X_train shape: (100000, 6)\n",
      "Features: ['IUCR', 'Primary Type', 'Arrest', 'Domestic', 'FBI Code', 'Year']\n"
     ]
    }
   ],
   "source": [
    "# Drop junk\n",
    "X_train = X_train.drop(columns=['ID', 'Case Number', 'Updated On', 'Date'], errors='ignore')\n",
    "\n",
    "# Booleans\n",
    "X_train['Arrest'] = X_train['Arrest'].astype(int)\n",
    "X_train['Domestic'] = X_train['Domestic'].astype(int)\n",
    "\n",
    "# Drop highly unique categorical columns for speed\n",
    "high_unique = ['Block', 'Description']\n",
    "X_train = X_train.drop(columns=high_unique, errors='ignore')\n",
    "X_train = X_train.drop(columns=['Ward', 'Community Area', 'Beat', 'District'], errors='ignore')\n",
    "\n",
    "# Encode remaining categorical variables\n",
    "cat_cols = ['Primary Type', 'IUCR', 'FBI Code']\n",
    "encoders = {}\n",
    "for col in cat_cols:\n",
    "    if col in X_train.columns:\n",
    "        le = LabelEncoder()\n",
    "        X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
    "        encoders[col] = le\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train[X_train.columns] = scaler.fit_transform(X_train[X_train.columns])\n",
    "\n",
    "print(f\"Final X_train shape: {X_train.shape}\")\n",
    "print(f\"Features: {X_train.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f65b9f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cross_validation_pytorch(X, y, k=5, batch_size=32, learning_rate=0.001, n_epochs=50):\n",
    "    # Robustly convert inputs to numeric and cast to float32\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_df = X.copy()\n",
    "    else:\n",
    "        X_df = pd.DataFrame(X)\n",
    "    X_df = X_df.apply(pd.to_numeric, errors='coerce')\n",
    "    # Fill numeric NaNs with column means (safe fallback)\n",
    "    X_df = X_df.fillna(X_df.mean())\n",
    "    X_arr = X_df.values.astype(np.float32)\n",
    "\n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        y_df = y.copy()\n",
    "    else:\n",
    "        y_df = pd.DataFrame(y)\n",
    "    y_df = y_df.apply(pd.to_numeric, errors='coerce')\n",
    "    y_df = y_df.fillna(y_df.mean()).fillna(0)\n",
    "    y_arr = y_df.values.astype(np.float32)\n",
    "    if y_arr.ndim == 1:\n",
    "        y_arr = y_arr.reshape(-1, 1)\n",
    "\n",
    "    #get input dimension\n",
    "    input_dim = X_arr.shape[1]\n",
    "    print(f\"Input dimension: {input_dim}\")\n",
    "    print(f\"Output dimension: {y_arr.shape[1]}\")\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_results = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'models': []\n",
    "    }\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_arr), 1):\n",
    "        print(f\"Training Fold {fold}/{k}\")\n",
    "\n",
    "        # Create tensors for this fold\n",
    "        X_train_fold = torch.tensor(X_arr[train_idx], dtype=torch.float32)\n",
    "        y_train_fold = torch.tensor(y_arr[train_idx], dtype=torch.float32)\n",
    "        X_val_fold = torch.tensor(X_arr[val_idx], dtype=torch.float32)\n",
    "        y_val_fold = torch.tensor(y_arr[val_idx], dtype=torch.float32)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_dataset = TensorDataset(X_train_fold, y_train_fold)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_dataset = TensorDataset(X_val_fold, y_val_fold)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize model with correct input dimension\n",
    "        torch.manual_seed(1234)\n",
    "        model = MyModel(input_dim=input_dim)  # PASS INPUT_DIM HERE\n",
    "        cost_function = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Adam instead of SGD\n",
    "\n",
    "        train_losses = []\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            model.train()\n",
    "            running_cost = 0.0\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = model(x_batch)\n",
    "                cost = cost_function(y_pred, y_batch)\n",
    "                cost.backward()\n",
    "                optimizer.step()\n",
    "                running_cost += cost.item() * x_batch.size(0)\n",
    "\n",
    "            epoch_train_loss = running_cost / len(X_train_fold)\n",
    "            train_losses.append(epoch_train_loss)\n",
    "            \n",
    "            # Print every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{n_epochs}: Train Loss = {epoch_train_loss:.6f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_running_cost = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in val_loader:\n",
    "                y_pred = model(x_batch)\n",
    "                cost = cost_function(y_pred, y_batch)\n",
    "                val_running_cost += cost.item() * x_batch.size(0)\n",
    "\n",
    "        val_loss = val_running_cost / len(X_val_fold)\n",
    "        final_train_loss = train_losses[-1] if len(train_losses) else None\n",
    "\n",
    "        fold_results['train_loss'].append(final_train_loss)\n",
    "        fold_results['val_loss'].append(val_loss)\n",
    "        fold_results['models'].append(model)\n",
    "\n",
    "        print(f\"\\nFold {fold} Results:\")\n",
    "        print(f\"  Final Train Loss: {final_train_loss:.6f}\")\n",
    "        print(f\"  Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "    # Summary statistics\n",
    "    avg_train_loss = np.mean([t for t in fold_results['train_loss'] if t is not None])\n",
    "    avg_val_loss = np.mean(fold_results['val_loss'])\n",
    "    std_val_loss = np.std(fold_results['val_loss'])\n",
    "    \n",
    "  \n",
    "    print(f\"K-Fold Cross-Validation Results (k={k})\")\n",
    "    print(f\"Average Train Loss: {avg_train_loss:.6f}\")\n",
    "    print(f\"Average Val Loss: {avg_val_loss:.6f} (+/- {std_val_loss:.6f})\")\n",
    "    print(f\"Individual Fold Val Losses: {[f'{loss:.6f}' for loss in fold_results['val_loss']]}\")\n",
    "\n",
    "    fold_results['avg_train_loss'] = avg_train_loss\n",
    "    fold_results['avg_val_loss'] = avg_val_loss\n",
    "    fold_results['std_val_loss'] = std_val_loss\n",
    "    return fold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3f43a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: 6\n",
      "Output dimension: 2\n",
      "Training Fold 1/5\n",
      "Epoch 10/50: Train Loss = 0.009081\n",
      "Epoch 20/50: Train Loss = 0.006073\n",
      "Epoch 30/50: Train Loss = 0.006105\n",
      "Epoch 40/50: Train Loss = 0.006059\n",
      "Epoch 50/50: Train Loss = 0.006083\n",
      "\n",
      "Fold 1 Results:\n",
      "  Final Train Loss: 0.006083\n",
      "  Validation Loss: 0.005958\n",
      "Training Fold 2/5\n",
      "Epoch 10/50: Train Loss = 0.009258\n",
      "Epoch 20/50: Train Loss = 0.006058\n",
      "Epoch 30/50: Train Loss = 0.006050\n",
      "Epoch 40/50: Train Loss = 0.006052\n",
      "Epoch 50/50: Train Loss = 0.006029\n",
      "\n",
      "Fold 2 Results:\n",
      "  Final Train Loss: 0.006029\n",
      "  Validation Loss: 0.006051\n",
      "Training Fold 3/5\n",
      "Epoch 10/50: Train Loss = 0.009135\n",
      "Epoch 20/50: Train Loss = 0.006008\n",
      "Epoch 30/50: Train Loss = 0.006035\n",
      "Epoch 40/50: Train Loss = 0.006023\n",
      "Epoch 50/50: Train Loss = 0.006052\n",
      "\n",
      "Fold 3 Results:\n",
      "  Final Train Loss: 0.006052\n",
      "  Validation Loss: 0.006727\n",
      "Training Fold 4/5\n",
      "Epoch 10/50: Train Loss = 0.008881\n",
      "Epoch 20/50: Train Loss = 0.006042\n",
      "Epoch 30/50: Train Loss = 0.006008\n",
      "Epoch 40/50: Train Loss = 0.006080\n",
      "Epoch 50/50: Train Loss = 0.006062\n",
      "\n",
      "Fold 4 Results:\n",
      "  Final Train Loss: 0.006062\n",
      "  Validation Loss: 0.005893\n",
      "Training Fold 5/5\n",
      "Epoch 10/50: Train Loss = 0.009022\n",
      "Epoch 20/50: Train Loss = 0.006014\n",
      "Epoch 30/50: Train Loss = 0.006059\n",
      "Epoch 40/50: Train Loss = 0.006039\n",
      "Epoch 50/50: Train Loss = 0.006088\n",
      "\n",
      "Fold 5 Results:\n",
      "  Final Train Loss: 0.006088\n",
      "  Validation Loss: 0.005642\n",
      "K-Fold Cross-Validation Results (k=5)\n",
      "Average Train Loss: 0.006063\n",
      "Average Val Loss: 0.006054 (+/- 0.000363)\n",
      "Individual Fold Val Losses: ['0.005958', '0.006051', '0.006727', '0.005893', '0.005642']\n",
      "\n",
      "Best fold (lowest val loss): 5\n",
      "Best val loss: 0.005642\n",
      "Train MSE for best fold: 0.005605\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = kfold_cross_validation_pytorch(\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        k=5,\n",
    "        batch_size=32,\n",
    "        learning_rate=0.001,  # Slightly higher learning rate\n",
    "        n_epochs=50  # Fewer epochs to start\n",
    "    )\n",
    "    \n",
    "    best_fold = np.argmin(results['val_loss'])\n",
    "\n",
    "    print(f\"\\nBest fold (lowest val loss): {np.argmin(results['val_loss']) + 1}\")\n",
    "    print(f\"Best val loss: {min(results['val_loss']):.6f}\")\n",
    "\n",
    "    best_model = results['models'][best_fold]\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    X_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "\n",
    "    best_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = best_model(X_tensor)\n",
    "        best_fold_train_mse = mse_loss(y_pred, y_tensor).item()\n",
    "\n",
    "    print(f\"Train MSE for best fold: {best_fold_train_mse:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
